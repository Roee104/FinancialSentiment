{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b22105a",
   "metadata": {},
   "source": [
    "Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b044af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Download punkt if necessary\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be9894",
   "metadata": {},
   "source": [
    "Load Frozen FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()  # no gradient\n",
    "\n",
    "label_map = {0: \"NEG\", 1: \"NEU\", 2: \"POS\"}\n",
    "\n",
    "def frozen_sentiment_predict(text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        out = model(**inputs)\n",
    "        probs = torch.softmax(out.logits, dim=-1).squeeze().cpu().numpy()\n",
    "    label_id = int(probs.argmax())\n",
    "    return label_map[label_id], float(probs[label_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47358245",
   "metadata": {},
   "source": [
    "Chunk & Predict for All Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the sampled folder exists\n",
    "os.makedirs(\"data/sampled\", exist_ok=True)\n",
    "\n",
    "CHUNK_OUT = \"../data/sampled/chunk_sentiments_frozen.jsonl\"\n",
    "with open(\"../data/sampled/10k_sample.jsonl\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as fin, \\\n",
    "     open(CHUNK_OUT, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in tqdm(fin, total=10000):\n",
    "        art = json.loads(line)\n",
    "        art_id = art.get(\"id\", None)\n",
    "        full_text = art.get(\"headline_summary\", \"\") + \" \" + art.get(\"body\", \"\")\n",
    "\n",
    "        # Break into 3-sentence chunks\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        sents = sent_tokenize(full_text)\n",
    "        chunks = []\n",
    "        for i in range(0, len(sents), 3):\n",
    "            chunk = \" \".join(sents[i : i + 3]).strip()\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "\n",
    "        # Predict sentiment for each chunk (on CPU)\n",
    "        chunk_results = []\n",
    "        for chunk in chunks:\n",
    "            lab, conf = frozen_sentiment_predict(chunk)\n",
    "            chunk_results.append({\"text\": chunk, \"label\": lab, \"confidence\": conf})\n",
    "\n",
    "        fout.write(json.dumps({\n",
    "            \"article_id\": art_id,\n",
    "            \"chunks\": chunk_results\n",
    "        }) + \"\\n\")\n",
    "\n",
    "print(\"✔ Saved chunk‐level sentiments to\", CHUNK_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af22028",
   "metadata": {},
   "source": [
    "Aggregate Chunk‐Level to Article‐Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_article_sentiment(chunk_results):\n",
    "    labels = [c[\"label\"] for c in chunk_results]\n",
    "    confidences = [c[\"confidence\"] for c in chunk_results]\n",
    "    count = Counter(labels)\n",
    "    top_two = count.most_common(2)\n",
    "    if len(top_two) == 1 or top_two[0][1] > top_two[1][1]:\n",
    "        article_label = top_two[0][0]\n",
    "    else:\n",
    "        tied = [lab for lab, cnt in top_two if cnt == top_two[0][1]]\n",
    "        avg_conf = {lab: np.mean([c[\"confidence\"] for c in chunk_results if c[\"label\"] == lab]) for lab in tied}\n",
    "        article_label = max(avg_conf, key=avg_conf.get)\n",
    "    rel_confs = [c[\"confidence\"] for c in chunk_results if c[\"label\"] == article_label]\n",
    "    article_conf = float(np.mean(rel_confs)) if rel_confs else 0.0\n",
    "    return article_label, article_conf\n",
    "\n",
    "AGG_OUT = \"../data/sampled/article_sentiments_frozen.csv\"\n",
    "rows = []\n",
    "with open(\"../data/sampled/chunk_sentiments_frozen.jsonl\", \"r\", encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        rec = json.loads(line)\n",
    "        art_id = rec[\"article_id\"]\n",
    "        art_lbl, art_conf = aggregate_article_sentiment(rec[\"chunks\"])\n",
    "        rows.append({\"article_id\": art_id, \"label\": art_lbl, \"confidence\": art_conf})\n",
    "\n",
    "pd.DataFrame(rows).to_csv(AGG_OUT, index=False, encoding=\"utf-8\")\n",
    "print(\"✔ Saved article‐level sentiments to\", AGG_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f046d8d",
   "metadata": {},
   "source": [
    "Quick Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff2b60",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"data/sampled/article_sentiments_frozen.csv\")\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"\\nConfidence stats:\")\n",
    "print(df[\"confidence\"].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
